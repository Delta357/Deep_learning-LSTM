{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fagkifMi68rc"
      },
      "outputs": [],
      "source": [
        "# Importando bibliotecas\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Importando biblioteca dataset imdb\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "# Importando biblioteca nltk stopwords\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Importando biblioteca rede neural\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "# Importando biblioteca keras tensorflow rede neural\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o conjunto de dados IMDB\n",
        "max_words = 2000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_words)"
      ],
      "metadata": {
        "id": "9n45WORB7qEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "qp1toZhg74-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "SQHKPr9175C2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pré-processamento dos dados\n",
        "max_review_length = 1000\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)"
      ],
      "metadata": {
        "id": "F9x5oTIN7735"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Rede Neural**"
      ],
      "metadata": {
        "id": "ai3ll7Rb8AoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir a arquitetura da rede neural LSTM\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, 128, input_length=max_review_length))\n",
        "model.add(LSTM(128, return_sequences=True))  # Adiciona uma camada LSTM adicional\n",
        "model.add(LSTM(64))  # Adiciona outra camada LSTM\n",
        "model.add(Dense(64, activation='relu'))  # Adiciona uma camada densa com ativação ReLU\n",
        "model.add(Dropout(0.5))  # Adiciona dropout para regularização\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compilar o modelo\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 5\n",
        "\n",
        "# Summario modelo\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "t8y69MRu7-DJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Treinar o modelo\n",
        "model_lstm = model.fit(X_train,\n",
        "          y_train,\n",
        "          validation_data=(X_test, y_test),\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs)"
      ],
      "metadata": {
        "id": "vMknyZGZ8IK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extrair as métricas de treinamento\n",
        "train_loss = model_lstm.history['loss']\n",
        "val_loss = model_lstm.history['val_loss']\n",
        "\n",
        "train_accuracy = model_lstm.history['accuracy']\n",
        "val_accuracy = model_lstm.history['val_accuracy']"
      ],
      "metadata": {
        "id": "Ez9bKa7aJNjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotar as métricas\n",
        "epochs_range = range(1, epochs + 1)\n",
        "\n",
        "plt.figure(figsize=(15.5, 10))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, train_loss, label='Loss de Treinamento')\n",
        "plt.plot(epochs_range, val_loss, label='Loss de Validação')\n",
        "plt.legend()\n",
        "plt.title('Loss de Treinamento e Validação')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, train_accuracy, label='Acurácia de Treinamento')\n",
        "plt.plot(epochs_range, val_accuracy, label='Acurácia de Validação')\n",
        "plt.legend()\n",
        "plt.title('Acurácia de Treinamento e Validação')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QL5b1UKn8nK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliar o modelo\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Acurácia Rede neural LSTM: %.2f%%\" % (scores[1] * 100))"
      ],
      "metadata": {
        "id": "yfNP9GBtIGQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazer previsões\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "WZBsLNkWIGUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprimir relatório de classificação\n",
        "print(\"Relatório de Classificação - Rede neural LSTM:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "y9zvWtv2IGX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar a matriz de confusão\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "print('Confusion matrix - Rede Neural - LSTM')\n",
        "print('\\nVerdadeiro Positivo(TP) = ', confusion[0,0])\n",
        "print('\\nVerdadeiro Negativo(TN) = ', confusion[1,1])\n",
        "print('\\nFalso Positivo(FP) = ', confusion[0,1])\n",
        "print('\\nFalso Negativo(FN) = ', confusion[1,0])"
      ],
      "metadata": {
        "id": "Pr9_gdvSIGam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot matriz confussão\n",
        "plt.figure(figsize=(10, 5))\n",
        "ax = plt.subplot()\n",
        "sns.heatmap(confusion, annot=True, ax = ax, fmt = \".1f\", cmap=\"Blues\");\n",
        "ax.set_title('Confusion Matrix - Rede Neural LSTM');\n",
        "ax.xaxis.set_ticklabels([\"Negativo\", \"Positivo\"]); ax.yaxis.set_ticklabels([\"Negativo\", \"Positivo\"]);\n",
        "plt.xlabel('Previsto')\n",
        "plt.ylabel('Verdadeiro')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lKGXBDQaJTk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Salvando modelo**"
      ],
      "metadata": {
        "id": "yyoLifHEJWOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvando rede neural\n",
        "from tensorflow.keras.models import save_model\n",
        "\n",
        "# Salvar o modelo treinado em um arquivo\n",
        "# 'modelo.h5' é o nome do arquivo onde o modelo será salvo\n",
        "model.save('modelo_sentiment_IMDB_2.h5')"
      ],
      "metadata": {
        "id": "TIj6bfpzJZhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusão**"
      ],
      "metadata": {
        "id": "-o4ryDg1Jejk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h27zxdhXJdOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Referência**"
      ],
      "metadata": {
        "id": "N2hN4PUUJjQx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dyPlYgUgJdSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7fzdE3QSJdWD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}